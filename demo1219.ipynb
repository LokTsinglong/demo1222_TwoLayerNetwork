{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11252cdc-1168-4e99-95db-8ac0d5e33f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "y=[0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0] # only for one sample, the highest one is for digit 2\n",
    "t=[0,0,1,0,0,0,0,0,0,0]#supposing 2 is the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122a40ce-5e7d-42bd-9aac-8293b1eeb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y,t):\n",
    "    return 0.5*np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86af6edd-ac2b-462e-aae6-938671c99325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdaaccc4-4d4f-4300-8596-2461cef1bce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2=[0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0] # the highest one is digit 7\n",
    "mean_squared_error(np.array(y2),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a34d00-7798-4174-8977-9244fee84883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta=1e-7 # avoid negative inf\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ccbe338-bc52-4866-ac2e-2e5f49a78208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(np.array(y),np.array(t)) # the smaller the index is, the better the result is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba67cd24-83f2-4851-bb14-51ebefe5552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(np.array(y2),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd121251-738f-475c-8f32-d466ec6b9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "mnist=fetch_openml('mnist_784',version=1)\n",
    "X,y=mnist['data'],mnist['target']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51429d5e-e144-401a-b101-d11733107f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b1fae29-6466-4c17-89fd-fcdc8015d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7566df-cc44-400f-bf6f-64620b8375a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# convert y_train to one hot coded label\u001b[39;00m\n\u001b[0;32m      2\u001b[0m int_y_train\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m oh_y_train\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39meye(int_y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(oh_y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mD:\\Anaconda-2024\\Lib\\site-packages\\numpy\\lib\\twodim_base.py:211\u001b[0m, in \u001b[0;36meye\u001b[1;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m M \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     M \u001b[38;5;241m=\u001b[39m N\n\u001b[1;32m--> 211\u001b[0m m \u001b[38;5;241m=\u001b[39m zeros((N, M), dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m M:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# convert y_train to one hot coded label\n",
    "int_y_train=y_train.astype(int)\n",
    "oh_y_train=np.eye(int_y_train)\n",
    "print(oh_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b46cfc1-51ad-4993-92f0-6d3a176aed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3084758-e5c5-415b-8ab1-9c87d7048345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 10)\n"
     ]
    }
   ],
   "source": [
    "npar_y_train=int_y_train.values\n",
    "oh_y_train=np.eye(10)[npar_y_train]\n",
    "print(oh_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65e1796e-b2f9-417d-b942-551e64d1ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 10)\n"
     ]
    }
   ],
   "source": [
    "# the second way to convert y_test\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder=OneHotEncoder(sparse_output=False)\n",
    "y_train_oh=encoder.fit_transform(npar_y_train.reshape(-1,1))\n",
    "print(y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7590ad70-d654-4071-9eae-649aff3f0e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([4816, 24057, 50800, 17930, 10389, 28128, 10370, 8950, 29706, 40788], dtype='int32')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m batch_mask\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(train_size,batch_size)\n\u001b[1;32m----> 4\u001b[0m X_train_batch\u001b[38;5;241m=\u001b[39mX_train[batch_mask]\n\u001b[0;32m      5\u001b[0m y_train_batch\u001b[38;5;241m=\u001b[39my_train[batch_mask]\n",
      "File \u001b[1;32mD:\\Anaconda-2024\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda-2024\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda-2024\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([4816, 24057, 50800, 17930, 10389, 28128, 10370, 8950, 29706, 40788], dtype='int32')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "train_size=X_train.shape[0] #row number\n",
    "batch_size=10\n",
    "batch_mask=np.random.choice(train_size,batch_size)\n",
    "X_train_batch=X_train[batch_mask]\n",
    "y_train_batch=y_train[batch_mask] # mistake！ I should use y_train_oh or oh_y_train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78d55b6a-118f-4a11-8da7-a9f213500eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This happens because DataFrames in Pandas use label-based indexing by default, \n",
    "whereas NumPy arrays use integer-based indexing.\n",
    "'''\n",
    "# solution is to explicitly use .iloc for row-based integer indexing \n",
    "train_size=X_train.shape[0] #row number\n",
    "batch_size=10\n",
    "batch_mask=np.random.choice(train_size,batch_size)\n",
    "X_train_batch=X_train.iloc[batch_mask] # the data type of X_train here is DataFrame\n",
    "y_train_batch=y_train_oh[batch_mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d21acdc-ad98-460a-ba0d-297be8c56d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):# the data type of  y and t here requires to be NumpyArray\n",
    "    if y.ndim==1: # deal with one piece of data\n",
    "        t=t.reshape(1,t.size)\n",
    "        y=y.reshape(1,y.size)\n",
    "        print(t)\n",
    "        print(y)\n",
    "    batch_size=y.shape[0]\n",
    "    return -np.sum(t*np.log(y+1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c15cd90-6667-4dbb-8489-5f843caeed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 0 0 0]]\n",
      "[[0.1  0.05 0.6  0.   0.05 0.1  0.   0.1  0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array([0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]) # only for one sample, the highest one is for digit 2\n",
    "t=np.array([0,0,1,0,0,0,0,0,0,0])\n",
    "cross_entropy_error(y,t) # why there is no print?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4111889-9bbf-4ab5-9820-fac751d83aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2670d76-2b33-4b54-814a-84d2379c1602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1  0.05 0.6  0.   0.05 0.1  0.   0.1  0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "y_re=y.reshape(1,y.size)\n",
    "print(y_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53e03352-59b1-42db-8252-4d5fba58879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(y_re.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "27f884a0-ef02-42e0-b8ab-327980c09f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\njust figure this example out and you will totally understand it\\ny = [[0.1, 0.7, 0.2],   # Predicted probabilities for sample 1\\n     [0.3, 0.4, 0.3],   # Predicted probabilities for sample 2\\n     [0.2, 0.2, 0.6]]   # Predicted probabilities for sample 3\\nt = [1, 2, 0]           # True labels for the 3 samples\\nbatch_size = 3\\nnp.arange(batch_size):  [0, 1, 2]\\ny[np.arange(batch_size), t]: [0.7, 0.3, 0.2]\\n'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim ==1 or t.ndim==1: # consider two situations\n",
    "        t=t.reshape(1,t.size)\n",
    "        y=y.reshape(1,y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]+1e-7))/batch_size\n",
    "    # it took me a lot of time to understand y[np.arrange(batch_size,t)]\n",
    "'''\n",
    "just figure this example out and you will totally understand it\n",
    "y = [[0.1, 0.7, 0.2],   # Predicted probabilities for sample 1\n",
    "     [0.3, 0.4, 0.3],   # Predicted probabilities for sample 2\n",
    "     [0.2, 0.2, 0.6]]   # Predicted probabilities for sample 3\n",
    "t = [1, 2, 0]           # True labels for the 3 samples\n",
    "batch_size = 3\n",
    "np.arange(batch_size):  [0, 1, 2]\n",
    "y[np.arange(batch_size), t]: [0.7, 0.3, 0.2]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27c17573-3074-439c-b40c-c1e1df3675f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_differentiation(f,x):\n",
    "    h=10e-50 # very small digit\n",
    "    return (f(x+h)-f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fc36fd6-eda3-4170-bfed-881e992f5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f,x):\n",
    "    h=1e-4\n",
    "    return (f(x+h)-f(x-h))/(2*h)# central difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c39a99d4-f98c-4d4c-9240-abdd88b76344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2+0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8cd242c-9c06-4cad-a658-69594013a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e4c09ce-ca4b-4a11-9036-cccabfd930d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd4e19cc-a2d6-4b0f-8f25-e64ee7db6705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2+x[1]**2\n",
    "    # return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51f98d93-b008-447a-9129-8d14517c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial derivative\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0+4.0*2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6e41144-adbe-437e-8ad8-8884f7417d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_tmp1,3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75ceb983-5ff4-4fb5-9981-8fd8f380c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_tmp2(x1):\n",
    "    return 3.0*2.0+x1*x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02291a57-ebae-4cdd-83ae-247a7a7a4dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_tmp2,4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c68524b5-25df-4465-aeb1-f9e27aab780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient\n",
    "def numerical_gradient(f,x): # input x is not a digit, but a vector!\n",
    "    h=1e-4 #0.0001\n",
    "    grad=np.zeros_like(x) #生成和x形状相同的数组\n",
    "    for idx in range(x.size):\n",
    "        tmp_val=x[idx]\n",
    "        # the calculation of f(x+h)\n",
    "        x[idx]=tmp_val+h\n",
    "        fxh1 = f(x)\n",
    "        # the calulation of f(x-h)\n",
    "        x[idx]=tmp_val-h\n",
    "        fxh2 = f(x)\n",
    "        grad[idx]=(fxh1-fxh2)/(2*h)\n",
    "        #central difference\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31302bf4-d031-4c6c-ab0e-35ea2b7715dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2,np.array([3.0,4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0881fec4-2cbf-4da3-a648-98f2ea3649aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f,init_x,lr=0.01,step_num=100): # lr, learning rate is a hyper parameter here\n",
    "    x=init_x\n",
    "    for i in range(step_num):\n",
    "        grad=numerical_gradient(f,x)\n",
    "        x-=lr*grad # x0=x0-lr*grad\n",
    "    return x\n",
    "#the implementation of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "788915f0-a4c8-49e6-a5d7-cec87bfdbff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0005, -0.0005])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2+x[1]**2\n",
    "init_x = np.array([-3.0,4.0])\n",
    "gradient_descent(function_2,init_x=init_x,lr=0.1,step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dff43369-5901-4cf4-bf61-aaf903b3a73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58985795e+13, -1.29524822e+12])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try different learning rate (hyper parameter)\n",
    "# learning rate=10.0\n",
    "init_x = np.array([-3.0,4.0])\n",
    "gradient_descent(function_2,init_x=init_x,lr=10,step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09713ba0-1d2c-4131-90aa-be8db2a974d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.00999994,  3.98999992])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate=1e-10\n",
    "init_x = np.array([-3.0,4.0])\n",
    "gradient_descent(function_2,init_x=init_x,lr=1e-10,step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88352680-1c5e-434f-ac9d-91ce1cdae0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x_max=np.max(x)\n",
    "    x_new=x-x_max #avoid overflow\n",
    "    exp_x=np.exp(x_new)\n",
    "    sum_exp_x=np.sum(exp_x)\n",
    "    y=exp_x/sum_exp_x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "242a50b6-9a51-4792-9ff1-4f581ff29c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim==1 or t.ndim==1: #1-D numpyArray and two situations\n",
    "        t.reshape(1,t.size)\n",
    "        y.reshape(1,y.size)\n",
    "    batch_size=y.shape[0] # the row number \n",
    "    return -np.sum(t*np.log(y+1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97a0fb29-29ef-44f3-ab7b-2fc0d4dc6f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "y=np.array([[1,2],\n",
    "           [3,4],\n",
    "           [5,6]])\n",
    "print(y.shape)\n",
    "print(y.shape[0])# the output of shape is a tuple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ba5cb7b-e728-4bdd-8dd4-7e3553afba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.23643446 -0.69837181  2.00259307]\n",
      " [-0.21100293  0.61444281 -0.12267541]]\n"
     ]
    }
   ],
   "source": [
    "W=np.random.randn(2,3)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5aa843d8-a2ec-432a-9c42-5d5044140bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:#define a class类\n",
    "    def __init__(self):\n",
    "        self.W=np.random.randn(2,3) # this is a constructor of class simpleNet Gaussian distribution\n",
    "        # there is no way to adjust the random state, which means we will get a various output each time we run this code\n",
    "        #just like a start point of gradient descent\n",
    "    def predict(self,x):\n",
    "        return np.dot(x,self.W)\n",
    "    def loss(self,x,t):\n",
    "        z=self.predict(x)\n",
    "        y=softmax(z) # the activating function is softmax(exp_a/sum_exp_a)\n",
    "        loss = cross_entropy_error(y,t) # loss function\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11e93093-af3a-457b-bd7b-d8e9f1832a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.33048457  2.55696978  0.84154757]\n",
      " [ 1.24943231  2.16893274  0.7920311 ]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet() # instantiate\n",
    "print(net.W) # weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b38f685a-cb32-4df7-ba04-148c2bdcefdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92619834 3.48622133 1.21775654]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([0.6,0.9])# x here means a vector so there is no need in capitalizing it \n",
    "p=net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9179b343-13b7-4877-a071-f928aac95327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fb5787e-c768-4790-b195-e37fbd695279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087305054392963"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=np.array([1,0,0])# correct answer tag\n",
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a613279-86c5-45d2-b713-7a6f7cdebe4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net\u001b[38;5;241m.\u001b[39mloss(x,t) \u001b[38;5;66;03m# a method .loss() from class simpleNet is encapsulated as a new function\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# f=lambda W : net.loss(x,t)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dW \u001b[38;5;241m=\u001b[39m numerical_gradient(f,net\u001b[38;5;241m.\u001b[39mW)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(dW)\n",
      "Cell \u001b[1;32mIn[65], line 6\u001b[0m, in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m      4\u001b[0m grad\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(x) \u001b[38;5;66;03m#生成和x形状相同的数组\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m----> 6\u001b[0m     tmp_val\u001b[38;5;241m=\u001b[39mx[idx]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# the calculation of f(x+h)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     x[idx]\u001b[38;5;241m=\u001b[39mtmp_val\u001b[38;5;241m+\u001b[39mh\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x,t) # a method .loss() from class simpleNet is encapsulated as a new function\n",
    "# f=lambda W : net.loss(x,t)\n",
    "dW = numerical_gradient(f,net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30b63245-5bf0-4ff8-b2a8-a1b4f4fb7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient for net.W mutiple dimension numpy array/ matrix\n",
    "def numerical_gradient_W(f,W): # we need to modify the original numerical gradient function to cater to the input of W matrix\n",
    "    h=1e-4 #0.0001\n",
    "    grad=np.zeros_like(W) #生成和W形状相同的matrix! to store the calculation output\n",
    "    for idx1 in range(W.shape[0]): \n",
    "        for idx2 in range(W.shape[1]):\n",
    "            tmp_val=W[idx1][idx2] # first to locate the entry we want to calcualte\n",
    "            # the calculation of f(x+h)\n",
    "            W[idx1][idx2]=tmp_val+h\n",
    "            fxh1 = f(x)\n",
    "            # the calulation of f(x-h)\n",
    "            W[idx1][idx2]=tmp_val-h\n",
    "            fxh2 = f(x)\n",
    "            grad[idx1][idx2]=(fxh1-fxh2)/(2*h)\n",
    "            #central difference\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee8eaf9e-ac09-4d85-bf8b-7f3045db51ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "y=np.array([[1,2],\n",
    "           [3,4],\n",
    "           [5,6]])\n",
    "print(y[0][0]) # get entry from a numpy array matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5fb60f6a-543d-417a-8fed-52df5b6f07ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1869061   0.16938085  0.01752688]\n",
      " [-0.28035916  0.25407177  0.02629104]]\n"
     ]
    }
   ],
   "source": [
    "dW = numerical_gradient_W(f,net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8e6cb6f4-c902-4093-9064-beceab015801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self,input_size,hidden_size,output_size,weight_init_std=0.01):\n",
    "        self.params={} # an empty dictionary\n",
    "        self.params['W1']=weight_init_std*np.random.randn(input_size,hidden_size) # backslash merely for line continuation\n",
    "        self.params['b1']=np.zeros(hidden_size)\n",
    "        self.params['W2']=weight_init_std*np.random.randn(hidden_size,output_size) # np.random.randn will create a new matrix\n",
    "        self.params['b2']=np.zeros(output_size)\n",
    "    def predict(self,x):\n",
    "        W1,W2 = self.params['W1'],self.params['W2']\n",
    "        b1,b2 = self.params['b1'],self.params['b2']\n",
    "        a1=np.dot(x,W1)+b1\n",
    "        Z1=sigmoid(a1)\n",
    "        a2=np.dot(Z1,W2)+b2\n",
    "        y=softmax(a2)\n",
    "        #no return here!!!!\n",
    "        return y\n",
    "    def loss(self,x,t):\n",
    "        y=self.predict(x)\n",
    "        return cross_entropy_error(y,t)\n",
    "    def accuracy(self,x,t):\n",
    "        y=self.predict(x)\n",
    "        y=np.argmax(y,axis=1)#axis=1 means row direction\n",
    "        t=np.argmax(t,axis=1)\n",
    "        accuracy=np.sum(y==t)/float(x.shape[0]) # x.shape[0] is the line number\n",
    "        return accuracy\n",
    "    def numerical_gradient(self,x,t):\n",
    "        loss_W=lambda W: self.loss(x,t)\n",
    "        grads={}# dont forget use an empty dictionary\n",
    "        grads['W1']=numerical_gradient_W(loss_W,self.params['W1'])\n",
    "        grads['b1']=numerical_gradient(loss_W,self.params['b1'])# We should use different numerical_gradient function!!\n",
    "        grads['W2']=numerical_gradient_W(loss_W,self.params['W2'])\n",
    "        grads['b2']=numerical_gradient(loss_W,self.params['b2'])\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b8ff1842-06f9-4c4e-a265-a69911712a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784,hidden_size=100,output_size=10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "395d09d8-3757-48e1-83b7-b030f3a9a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "453da99e-10ac-4078-a852-a3dca01b09f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x=np.random.rand(100,784)# forged input data\n",
    "y=net.predict(x)\n",
    "t=np.random.rand(100,10)#forged labels\n",
    "grads=net.numerical_gradient(x,t)\n",
    "print(grads['W1'].shape)\n",
    "print(grads['b1'].shape)\n",
    "print(grads['W2'].shape)\n",
    "print(grads['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "af97e055-8791-4620-9054-0a870e2cbf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape) # because I forgot return in predict method :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "07a8d072-74c2-415a-82ee-2281f5c278de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params['b1'].shape is(100,) and params['b2'].shape is (10,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"params['b1'].shape is{net.params['b1'].shape} and params['b2'].shape is {net.params['b2'].shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b7b81cde-dcc3-448f-a8f4-306587ebfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist project\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "mnist=fetch_openml('mnist_784',version=1)\n",
    "X,y=mnist['data'],mnist['target'] # X is DataFrame, y is Series \n",
    "#the target y or t is of dtype='category'\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c9d4e324-85f0-4ef6-a969-5b03995c44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "npar_X,npar_y = X.values, y.astype(int).values\n",
    "X_train,X_test,y_train,y_test = train_test_split(npar_X,npar_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3cf935d2-22d3-47cb-90cb-cc6d376598e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 10)\n",
      "(14000, 10)\n"
     ]
    }
   ],
   "source": [
    "encoder=OneHotEncoder(sparse_output=False) # get y one_hot encoded\n",
    "y_train_oh=encoder.fit_transform(y_train.reshape(-1,1))\n",
    "y_test_oh=encoder.fit_transform(y_test.reshape(-1,1))\n",
    "print(y_train_oh.shape)\n",
    "print(y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c6f5587f-0617-4061-80a7-86a27a8ac267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fa463035-0f3d-4df4-9e24-c4a9538bdafa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,) (100,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m t_batch\u001b[38;5;241m=\u001b[39my_train[batch_mask]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#gradient calculation\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m grad\u001b[38;5;241m=\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mnumerical_gradient(X_batch,t_batch)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#renew the weight and bias parameters\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[125], line 29\u001b[0m, in \u001b[0;36mTwoLayerNet.numerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     27\u001b[0m loss_W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m W: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x,t)\n\u001b[0;32m     28\u001b[0m grads\u001b[38;5;241m=\u001b[39m{}\u001b[38;5;66;03m# dont forget use an empty dictionary\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnumerical_gradient_W(loss_W,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     30\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnumerical_gradient(loss_W,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;66;03m# We should use different numerical_gradient function!!\u001b[39;00m\n\u001b[0;32m     31\u001b[0m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnumerical_gradient_W(loss_W,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[97], line 10\u001b[0m, in \u001b[0;36mnumerical_gradient_W\u001b[1;34m(f, W)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# the calculation of f(x+h)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m W[idx1][idx2]\u001b[38;5;241m=\u001b[39mtmp_val\u001b[38;5;241m+\u001b[39mh\n\u001b[1;32m---> 10\u001b[0m fxh1 \u001b[38;5;241m=\u001b[39m f(x)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# the calulation of f(x-h)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m W[idx1][idx2]\u001b[38;5;241m=\u001b[39mtmp_val\u001b[38;5;241m-\u001b[39mh\n",
      "Cell \u001b[1;32mIn[125], line 27\u001b[0m, in \u001b[0;36mTwoLayerNet.numerical_gradient.<locals>.<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumerical_gradient\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,t):\n\u001b[1;32m---> 27\u001b[0m     loss_W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m W: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x,t)\n\u001b[0;32m     28\u001b[0m     grads\u001b[38;5;241m=\u001b[39m{}\u001b[38;5;66;03m# dont forget use an empty dictionary\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnumerical_gradient_W(loss_W,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[125], line 19\u001b[0m, in \u001b[0;36mTwoLayerNet.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,t):\n\u001b[0;32m     18\u001b[0m     y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x)\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_entropy_error(y,t)\n",
      "Cell \u001b[1;32mIn[79], line 6\u001b[0m, in \u001b[0;36mcross_entropy_error\u001b[1;34m(y, t)\u001b[0m\n\u001b[0;32m      4\u001b[0m     y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,y\u001b[38;5;241m.\u001b[39msize)\n\u001b[0;32m      5\u001b[0m batch_size\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# the row number \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(t\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(y\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-7\u001b[39m))\u001b[38;5;241m/\u001b[39mbatch_size\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,) (100,10) "
     ]
    }
   ],
   "source": [
    "#setting hyper parameter\n",
    "iters_num=10000\n",
    "train_size=X_train.shape[0]\n",
    "batch_size=100\n",
    "learning_rate=0.1\n",
    "train_loss_list=[]#an empty list\n",
    "network=TwoLayerNet(input_size=784,hidden_size=50,output_size=10)\n",
    "#iteration\n",
    "for i in range(iters_num):\n",
    "    #get mini_batch\n",
    "    batch_mask=np.random.choice(train_size,batch_size)\n",
    "    X_batch=X_train[batch_mask]\n",
    "    t_batch=y_train[batch_mask]\n",
    "    #gradient calculation\n",
    "    grad=network.numerical_gradient(X_batch,t_batch)\n",
    "    #renew the weight and bias parameters\n",
    "    for key in ('W1','b1','W2','b2'):\n",
    "        network.params[key]-=learning_rate*grad[key]\n",
    "    loss=network.loss(X_batch,t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58b80b-d4cd-4527-9625-66293ec4d4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
